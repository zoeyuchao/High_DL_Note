# 机器博弈

## why games

- 一种人工智能
- TD-Gammon 1992年 开始用强化学习和神经网络结合
- 冯诺依曼 证明minimax定理，解二人博弈的一种方法。大家take的 action都是最优的
- game tree，minimax
- MC Tree search 走到了之前没有展开过的节点，就会按照某种策略先展开一个节点，然后仿真一下，然后back一下。用不停的sample的方式。

## Go

- Go很难，因为策略太多了。

### AlphaGo

- MC Tree Search和强化学习相结合
- SL policy去初始化一个RL policy（用高手策略 去 探索 展开节点）
- RL policy最后没有用来打比赛，间接用了。有一个value network用来评价。

### AlphaGoZero

- 没有人类策略，自己跟自己对打
- 网络架构，既输出value，又输出362维的action的概率

## 德州扑克

- 不可观测信息，别人的手牌看不到。

- libratus 2人

  - action空间很大，要做abstraction，用CFR，过了几轮之后就要换策略，不然误差就会很大。

- pluribus 多人 

  - 找到的纳什不好使 多个纳什，不一定大家take的是一个纳什

### 麻将

  - Suphx 微软自己的
  - 人类从中也会学习到更好的策略
### 总结
- 有趣 eye-catching
- 

